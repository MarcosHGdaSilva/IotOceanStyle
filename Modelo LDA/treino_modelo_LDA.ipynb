{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pycaret.classification import save_model, setup\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import (classification_report)\n",
    "from sklearn.model_selection import cross_val_score, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminhos para as pastas de áudio\n",
    "pasta_ruido = r'../audios/audios_treinamento/classe_ruido'\n",
    "pasta_barco = r'../audios/audios_treinamento/classe_barco'\n",
    "\n",
    "# Função para extrair features dos áudios\n",
    "def extract_features(file_path):\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "    features = {\n",
    "        'chroma_stft': librosa.feature.chroma_stft(y=y, sr=sr).mean(),\n",
    "        'chroma_cqt': librosa.feature.chroma_cqt(y=y, sr=sr).mean(),\n",
    "        'chroma_cens': librosa.feature.chroma_cens(y=y, sr=sr).mean(),\n",
    "        'rmse': librosa.feature.rms(y=y).mean(),\n",
    "        'spectral_centroid': librosa.feature.spectral_centroid(y=y, sr=sr).mean(),\n",
    "        'spectral_bandwidth': librosa.feature.spectral_bandwidth(y=y, sr=sr).mean(),\n",
    "        'spectral_contrast': librosa.feature.spectral_contrast(y=y, sr=sr).mean(),\n",
    "        'spectral_flatness': librosa.feature.spectral_flatness(y=y).mean(),\n",
    "        'spectral_rolloff': librosa.feature.spectral_rolloff(y=y, sr=sr).mean(),\n",
    "        'zero_crossing_rate': librosa.feature.zero_crossing_rate(y).mean(),\n",
    "        'mfcc1': librosa.feature.mfcc(y=y, sr=sr)[0].mean(),\n",
    "        'mfcc2': librosa.feature.mfcc(y=y, sr=sr)[1].mean(),\n",
    "        'mfcc3': librosa.feature.mfcc(y=y, sr=sr)[2].mean(),\n",
    "        # 'mfcc4': librosa.feature.mfcc(y=y, sr=sr)[3].mean(),\n",
    "        # 'mfcc5': librosa.feature.mfcc(y=y, sr=sr)[4].mean(),\n",
    "        # 'mfcc6': librosa.feature.mfcc(y=y, sr=sr)[5].mean(),\n",
    "        # 'mfcc7': librosa.feature.mfcc(y=y, sr=sr)[6].mean(),\n",
    "        # 'mfcc8': librosa.feature.mfcc(y=y, sr=sr)[7].mean(),\n",
    "        # 'mfcc9': librosa.feature.mfcc(y=y, sr=sr)[8].mean(),\n",
    "        # 'mfcc10': librosa.feature.mfcc(y=y, sr=sr)[9].mean(),\n",
    "        # 'mfcc11': librosa.feature.mfcc(y=y, sr=sr)[10].mean(),\n",
    "        # 'mfcc12': librosa.feature.mfcc(y=y, sr=sr)[11].mean(),\n",
    "        # 'mfcc13': librosa.feature.mfcc(y=y, sr=sr)[12].mean(),\n",
    "        #'tempo': librosa.beat.tempo(y=y, sr=sr)[0]\n",
    "    }\n",
    "    return features\n",
    "\n",
    "# Função para processar as pastas e adicionar os dados ao DataFrame\n",
    "def verifica_pastas(folder_path, label):\n",
    "    data = []\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        if file_path.endswith('.wav'):\n",
    "            features = extract_features(file_path)\n",
    "            features['label'] = label\n",
    "            data.append(features)\n",
    "    return data\n",
    "\n",
    "# Processar as duas pastas sendo cada uma uma classe\n",
    "dados_ruido = verifica_pastas(pasta_ruido, 1)\n",
    "dados_barco = verifica_pastas(pasta_barco, 2)\n",
    "\n",
    "# Combinar os dados e criar um DataFrame\n",
    "data = dados_ruido + dados_barco\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Salvar em um arquivo CSV\n",
    "df.to_csv(\"CSV\\\\features_audios_classificados.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.read_csv(\"CSV\\\\features_audios_classificados.csv\")\n",
    "X = dados.drop(columns=['label'])\n",
    "y = dados['label']\n",
    "\n",
    "# Dividir os dados em conjunto de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "\n",
    "# Treinando o modelo LDA\n",
    "lda_model = LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,\n",
    "                           priors=None, shrinkage=None, solver='svd',\n",
    "                           store_covariance=False, tol=0.0001)\n",
    "lda_model.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsões e avaliar o modelo\n",
    "y_pred = lda_model.predict(X_test)\n",
    "print(\"Relatório de Classificação para LDA:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "clf1 = setup(data=dados, target='label', session_id=123)\n",
    "save_model(lda_model, 'Modelo_LDA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "scores = cross_val_score(lda_model, X, y, cv=5)\n",
    "print(f\"Cross-validation scores: {scores}\")\n",
    "print(f\"Mean cross-validation score: {np.mean(scores)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
