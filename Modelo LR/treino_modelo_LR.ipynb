{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pycaret.classification import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (accuracy_score, classification_report,\n",
    "                             confusion_matrix, mean_squared_error, r2_score)\n",
    "from sklearn.model_selection import cross_val_score, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminhos para as pastas de áudio\n",
    "pasta_ruido = r'../audios/audios_treinamento/classe_ruido'\n",
    "pasta_barco = r'../audios/audios_treinamento/classe_barco'\n",
    "\n",
    "# Função para extrair features dos áudios\n",
    "def extract_features(file_path):\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "    features = {\n",
    "        'chroma_stft': librosa.feature.chroma_stft(y=y, sr=sr).mean(),\n",
    "        'chroma_cqt': librosa.feature.chroma_cqt(y=y, sr=sr).mean(),\n",
    "        'chroma_cens': librosa.feature.chroma_cens(y=y, sr=sr).mean(),\n",
    "        'rmse': librosa.feature.rms(y=y).mean(),\n",
    "        'spectral_centroid': librosa.feature.spectral_centroid(y=y, sr=sr).mean(),\n",
    "        'spectral_bandwidth': librosa.feature.spectral_bandwidth(y=y, sr=sr).mean(),\n",
    "        'spectral_contrast': librosa.feature.spectral_contrast(y=y, sr=sr).mean(),\n",
    "        'spectral_flatness': librosa.feature.spectral_flatness(y=y).mean(),\n",
    "        'spectral_rolloff': librosa.feature.spectral_rolloff(y=y, sr=sr).mean(),\n",
    "        'rolloff': librosa.feature.spectral_rolloff(y=y, sr=sr).mean(),\n",
    "        'zero_crossing_rate': librosa.feature.zero_crossing_rate(y).mean(),\n",
    "        'mfcc1': librosa.feature.mfcc(y=y, sr=sr)[0].mean(),\n",
    "        'mfcc2': librosa.feature.mfcc(y=y, sr=sr)[1].mean(),\n",
    "        'mfcc3': librosa.feature.mfcc(y=y, sr=sr)[2].mean(),\n",
    "        # 'mfcc4': librosa.feature.mfcc(y=y, sr=sr)[3].mean(),\n",
    "        # 'mfcc5': librosa.feature.mfcc(y=y, sr=sr)[4].mean(),\n",
    "        # 'mfcc6': librosa.feature.mfcc(y=y, sr=sr)[5].mean(),\n",
    "        # 'mfcc7': librosa.feature.mfcc(y=y, sr=sr)[6].mean(),\n",
    "        # 'mfcc8': librosa.feature.mfcc(y=y, sr=sr)[7].mean(),\n",
    "        # 'mfcc9': librosa.feature.mfcc(y=y, sr=sr)[8].mean(),\n",
    "        # 'mfcc10': librosa.feature.mfcc(y=y, sr=sr)[9].mean(),\n",
    "        # 'mfcc11': librosa.feature.mfcc(y=y, sr=sr)[10].mean(),\n",
    "        # 'mfcc12': librosa.feature.mfcc(y=y, sr=sr)[11].mean(),\n",
    "        # 'mfcc13': librosa.feature.mfcc(y=y, sr=sr)[12].mean(),\n",
    "        #'tempo': librosa.beat.tempo(y=y, sr=sr)[0]\n",
    "    }\n",
    "    return features\n",
    "\n",
    "# Função para processar as pastas e adicionar os dados ao DataFrame\n",
    "def verifica_pastas(folder_path, label):\n",
    "    data = []\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        if file_path.endswith('.wav'):\n",
    "            features = extract_features(file_path)\n",
    "            features['label'] = label\n",
    "            data.append(features)\n",
    "    return data\n",
    "\n",
    "# Processar as duas pastas sendo cada uma uma classe\n",
    "dados_ruido = verifica_pastas(pasta_ruido, 1)\n",
    "dados_barco = verifica_pastas(pasta_barco, 2)\n",
    "\n",
    "# Combinar os dados e criar um DataFrame\n",
    "data = dados_ruido + dados_barco\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Salvar em um arquivo CSV\n",
    "df.to_csv(\"csv/features_audios_classificados.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relatório de Classificação para LDA:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.92      0.96        13\n",
      "           2       0.95      1.00      0.98        20\n",
      "\n",
      "    accuracy                           0.97        33\n",
      "   macro avg       0.98      0.96      0.97        33\n",
      "weighted avg       0.97      0.97      0.97        33\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b5b09_row9_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b5b09\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b5b09_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_b5b09_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b5b09_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_b5b09_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_b5b09_row0_col1\" class=\"data row0 col1\" >123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5b09_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_b5b09_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_b5b09_row1_col1\" class=\"data row1 col1\" >label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5b09_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_b5b09_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_b5b09_row2_col1\" class=\"data row2 col1\" >Binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5b09_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_b5b09_row3_col0\" class=\"data row3 col0\" >Target mapping</td>\n",
       "      <td id=\"T_b5b09_row3_col1\" class=\"data row3 col1\" >1: 0, 2: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5b09_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_b5b09_row4_col0\" class=\"data row4 col0\" >Original data shape</td>\n",
       "      <td id=\"T_b5b09_row4_col1\" class=\"data row4 col1\" >(66, 15)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5b09_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_b5b09_row5_col0\" class=\"data row5 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_b5b09_row5_col1\" class=\"data row5 col1\" >(66, 15)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5b09_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_b5b09_row6_col0\" class=\"data row6 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_b5b09_row6_col1\" class=\"data row6 col1\" >(46, 15)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5b09_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_b5b09_row7_col0\" class=\"data row7 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_b5b09_row7_col1\" class=\"data row7 col1\" >(20, 15)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5b09_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_b5b09_row8_col0\" class=\"data row8 col0\" >Numeric features</td>\n",
       "      <td id=\"T_b5b09_row8_col1\" class=\"data row8 col1\" >14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5b09_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_b5b09_row9_col0\" class=\"data row9 col0\" >Preprocess</td>\n",
       "      <td id=\"T_b5b09_row9_col1\" class=\"data row9 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5b09_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_b5b09_row10_col0\" class=\"data row10 col0\" >Imputation type</td>\n",
       "      <td id=\"T_b5b09_row10_col1\" class=\"data row10 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5b09_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_b5b09_row11_col0\" class=\"data row11 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_b5b09_row11_col1\" class=\"data row11 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5b09_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_b5b09_row12_col0\" class=\"data row12 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_b5b09_row12_col1\" class=\"data row12 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5b09_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_b5b09_row13_col0\" class=\"data row13 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_b5b09_row13_col1\" class=\"data row13 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5b09_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_b5b09_row14_col0\" class=\"data row14 col0\" >Fold Number</td>\n",
       "      <td id=\"T_b5b09_row14_col1\" class=\"data row14 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5b09_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_b5b09_row15_col0\" class=\"data row15 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_b5b09_row15_col1\" class=\"data row15 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5b09_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_b5b09_row16_col0\" class=\"data row16 col0\" >Use GPU</td>\n",
       "      <td id=\"T_b5b09_row16_col1\" class=\"data row16 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5b09_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_b5b09_row17_col0\" class=\"data row17 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_b5b09_row17_col1\" class=\"data row17 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5b09_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_b5b09_row18_col0\" class=\"data row18 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_b5b09_row18_col1\" class=\"data row18 col1\" >clf-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5b09_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_b5b09_row19_col0\" class=\"data row19 col0\" >USI</td>\n",
       "      <td id=\"T_b5b09_row19_col1\" class=\"data row19 col1\" >74e7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1e4310b6b90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Saved\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Pipeline(memory=Memory(location=None),\n",
       "          steps=[('label_encoding',\n",
       "                  TransformerWrapperWithInverse(exclude=None, include=None,\n",
       "                                                transformer=LabelEncoder())),\n",
       "                 ('numerical_imputer',\n",
       "                  TransformerWrapper(exclude=None,\n",
       "                                     include=['chroma_stft', 'chroma_cqt',\n",
       "                                              'chroma_cens', 'rmse',\n",
       "                                              'spectral_centroid',\n",
       "                                              'spectral_bandwidth',\n",
       "                                              'spectral_contrast',\n",
       "                                              'spectral_flatness',\n",
       "                                              'spectral_r...\n",
       "                                                               fill_value=None,\n",
       "                                                               keep_empty_features=False,\n",
       "                                                               missing_values=nan,\n",
       "                                                               strategy='most_frequent'))),\n",
       "                 ('trained_model',\n",
       "                  LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                     fit_intercept=True, intercept_scaling=1,\n",
       "                                     l1_ratio=None, max_iter=1000,\n",
       "                                     multi_class='auto', n_jobs=None,\n",
       "                                     penalty='l2', random_state=123,\n",
       "                                     solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                     warm_start=False))],\n",
       "          verbose=False),\n",
       " 'Modelo_LDA.pkl')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados = pd.read_csv(\"csv/features_audios_classificados.csv\")\n",
    "X = dados.drop(columns=['label'])\n",
    "y = dados['label']\n",
    "\n",
    "# Dividir os dados em conjunto de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "\n",
    "# Treinando o modelo LDA\n",
    "lr_model = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
    "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
    "                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsões e avaliar o modelo\n",
    "y_pred = lr_model.predict(X_test)\n",
    "print(\"Relatório de Classificação para LDA:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "clf1 = setup(data=dados, target='label', session_id=123)\n",
    "save_model(lr_model, 'Modelo_LDA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.85714286 1.         0.84615385 1.         0.92307692]\n",
      "Mean cross-validation score: 0.9252747252747253\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "scores = cross_val_score(lr_model, X, y, cv=5)\n",
    "print(f\"Cross-validation scores: {scores}\")\n",
    "print(f\"Mean cross-validation score: {np.mean(scores)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
