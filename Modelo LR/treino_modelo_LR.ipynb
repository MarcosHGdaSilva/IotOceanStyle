{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importação de Bibliotecas\n",
    "Nesta célula, importamos diversas bibliotecas essenciais para o projeto. Utilizamos `os` para manipulação de diretórios, `librosa` para processamento de áudio, `numpy` e `pandas` para manipulação de dados, `pycaret` para facilitação do processo de modelagem, `sklearn` para o modelo de Regressão Logística e avaliação de desempenho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "from pycaret.classification import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (accuracy_score, classification_report,\n",
    "                             confusion_matrix, mean_squared_error, r2_score)\n",
    "from sklearn.model_selection import cross_val_score, train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exibição de Espectrograma\n",
    "Nesta célula, criamos uma função `plot_spectrogram` que exibe o espectrograma de um arquivo de áudio. Usamos `librosa` para carregar o arquivo e calcular o espectrograma de frequência mel, que é exibido usando `matplotlib`. A função é exemplificada com um arquivo da pasta de áudio de ruído.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectrogram(file_path):\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    S = librosa.feature.melspectrogram(y, sr=sr, n_mels=128)\n",
    "    S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "    librosa.display.specshow(S_dB, sr=sr, x_axis='time', y_axis='mel')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title('Mel-frequency spectrogram')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exibição de Gráfico de Áudio\n",
    "Nesta célula, criamos uma função `plot_waveform` que exibe o gráfico de um arquivo de áudio. Usamos `librosa` para carregar o arquivo e `matplotlib` para exibir a forma de onda. A função é exemplificada com o mesmo arquivo da célula anterior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_waveform(file_path):\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.waveshow(y, sr=sr)\n",
    "    plt.title('Waveform')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definição dos Caminhos e Função para Extração de Features\n",
    "Definimos os caminhos para os diretórios contendo os áudios das classes 'ruído' e 'barco'. A função `extract_features` é responsável por extrair várias características dos arquivos de áudio usando a biblioteca `librosa`. Esses recursos incluem medidas espectrais e MFCCs (Mel-Frequency Cepstral Coefficients), que são comumente usados na análise de áudio. Em seguida, combinamos os dados extraídos e os salvamos em um arquivo CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminhos para as pastas de áudio\n",
    "pasta_ruido = r'../audios/audios_treinamento/classe_ruido'\n",
    "pasta_barco = r'../audios/audios_treinamento/classe_barco'\n",
    "\n",
    "# Função para extrair features dos áudios\n",
    "def extract_features(file_path):\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "    features = {\n",
    "        'chroma_stft': librosa.feature.chroma_stft(y=y, sr=sr).mean(),\n",
    "        'chroma_cqt': librosa.feature.chroma_cqt(y=y, sr=sr).mean(),\n",
    "        'chroma_cens': librosa.feature.chroma_cens(y=y, sr=sr).mean(),\n",
    "        'rmse': librosa.feature.rms(y=y).mean(),\n",
    "        'spectral_centroid': librosa.feature.spectral_centroid(y=y, sr=sr).mean(),\n",
    "        'spectral_bandwidth': librosa.feature.spectral_bandwidth(y=y, sr=sr).mean(),\n",
    "        'spectral_contrast': librosa.feature.spectral_contrast(y=y, sr=sr).mean(),\n",
    "        'spectral_flatness': librosa.feature.spectral_flatness(y=y).mean(),\n",
    "        'spectral_rolloff': librosa.feature.spectral_rolloff(y=y, sr=sr).mean(),\n",
    "        'zero_crossing_rate': librosa.feature.zero_crossing_rate(y).mean(),\n",
    "        'mfcc1': librosa.feature.mfcc(y=y, sr=sr)[0].mean(),\n",
    "        'mfcc2': librosa.feature.mfcc(y=y, sr=sr)[1].mean(),\n",
    "        'mfcc3': librosa.feature.mfcc(y=y, sr=sr)[2].mean(),\n",
    "        # 'mfcc4': librosa.feature.mfcc(y=y, sr=sr)[3].mean(),\n",
    "        # 'mfcc5': librosa.feature.mfcc(y=y, sr=sr)[4].mean(),\n",
    "        # 'mfcc6': librosa.feature.mfcc(y=y, sr=sr)[5].mean(),\n",
    "        # 'mfcc7': librosa.feature.mfcc(y=y, sr=sr)[6].mean(),\n",
    "        # 'mfcc8': librosa.feature.mfcc(y=y, sr=sr)[7].mean(),\n",
    "        # 'mfcc9': librosa.feature.mfcc(y=y, sr=sr)[8].mean(),\n",
    "        # 'mfcc10': librosa.feature.mfcc(y=y, sr=sr)[9].mean(),\n",
    "        # 'mfcc11': librosa.feature.mfcc(y=y, sr=sr)[10].mean(),\n",
    "        # 'mfcc12': librosa.feature.mfcc(y=y, sr=sr)[11].mean(),\n",
    "        # 'mfcc13': librosa.feature.mfcc(y=y, sr=sr)[12].mean(),\n",
    "        #'tempo': librosa.beat.tempo(y=y, sr=sr)[0]\n",
    "    }\n",
    "    return features\n",
    "\n",
    "# Função para processar as pastas e adicionar os dados ao DataFrame\n",
    "def verifica_pastas(folder_path, label):\n",
    "    data = []\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        if file_path.endswith('.wav'):\n",
    "            features = extract_features(file_path)\n",
    "            features['label'] = label\n",
    "            data.append(features)\n",
    "    return data\n",
    "\n",
    "# Processar as duas pastas sendo cada uma uma classe\n",
    "dados_ruido = verifica_pastas(pasta_ruido, 1)\n",
    "dados_barco = verifica_pastas(pasta_barco, 2)\n",
    "\n",
    "# Combinar os dados e criar um DataFrame\n",
    "data = dados_ruido + dados_barco\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Salvar em um arquivo CSV\n",
    "df.to_csv(\"csv/features_audios_classificados.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exibição do Espectrograma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(pasta_ruido, os.listdir(pasta_ruido)[0])\n",
    "plot_spectrogram(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exibição de Gráfico de Áudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_waveform(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento do Modelo de Regressão Logística\n",
    "Carregamos os dados salvos no CSV e separamos os atributos (`X`) e os rótulos (`y`). Criamos uma instância do modelo `LogisticRegression` e a treinamos com os dados. Em seguida, avaliamos o modelo utilizando validação cruzada, calculando a precisão média das predições."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.85714286 0.92857143 1.         1.         1.        ]\n",
      "Mean cross-validation score: 0.9571428571428571\n"
     ]
    }
   ],
   "source": [
    "dados = pd.read_csv(\"csv/features_audios_classificados.csv\")\n",
    "X = dados.drop(columns=['label'])\n",
    "y = dados['label']\n",
    "\n",
    "# Dividir os dados em conjunto de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "\n",
    "# Treinando o modelo LDA\n",
    "lr_model = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
    "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
    "                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "scores = cross_val_score(lr_model, X, y, cv=5)\n",
    "print(f\"Cross-validation scores: {scores}\")\n",
    "print(f\"Mean cross-validation score: {np.mean(scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliação Adicional do Modelo\n",
    "Dividimos o conjunto de dados em treinamento e teste para realizar uma avaliação adicional do modelo. Treinamos o modelo com o conjunto de treinamento e geramos previsões para o conjunto de teste. O relatório de classificação é gerado para avaliar o desempenho do modelo em termos de métricas como precisão, recall e F1-score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relatório de Classificação para LDA:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      1.00      0.97        14\n",
      "           2       1.00      0.95      0.97        20\n",
      "\n",
      "    accuracy                           0.97        34\n",
      "   macro avg       0.97      0.97      0.97        34\n",
      "weighted avg       0.97      0.97      0.97        34\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fazer previsões e avaliar o modelo\n",
    "y_pred = lr_model.predict(X_test)\n",
    "print(\"Relatório de Classificação para LDA:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuração do Ambiente e Salvamento do Modelo\n",
    "Utilizamos o `setup` do `pycaret` para configurar o ambiente de classificação com os dados e o alvo definidos. Finalmente, salvamos o modelo treinado usando a função `save_model` do `pycaret`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e33e5_row9_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e33e5\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e33e5_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_e33e5_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e33e5_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_e33e5_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_e33e5_row0_col1\" class=\"data row0 col1\" >123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e33e5_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_e33e5_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_e33e5_row1_col1\" class=\"data row1 col1\" >label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e33e5_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_e33e5_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_e33e5_row2_col1\" class=\"data row2 col1\" >Binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e33e5_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_e33e5_row3_col0\" class=\"data row3 col0\" >Target mapping</td>\n",
       "      <td id=\"T_e33e5_row3_col1\" class=\"data row3 col1\" >1: 0, 2: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e33e5_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_e33e5_row4_col0\" class=\"data row4 col0\" >Original data shape</td>\n",
       "      <td id=\"T_e33e5_row4_col1\" class=\"data row4 col1\" >(67, 14)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e33e5_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_e33e5_row5_col0\" class=\"data row5 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_e33e5_row5_col1\" class=\"data row5 col1\" >(67, 14)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e33e5_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_e33e5_row6_col0\" class=\"data row6 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_e33e5_row6_col1\" class=\"data row6 col1\" >(46, 14)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e33e5_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_e33e5_row7_col0\" class=\"data row7 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_e33e5_row7_col1\" class=\"data row7 col1\" >(21, 14)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e33e5_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_e33e5_row8_col0\" class=\"data row8 col0\" >Numeric features</td>\n",
       "      <td id=\"T_e33e5_row8_col1\" class=\"data row8 col1\" >13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e33e5_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_e33e5_row9_col0\" class=\"data row9 col0\" >Preprocess</td>\n",
       "      <td id=\"T_e33e5_row9_col1\" class=\"data row9 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e33e5_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_e33e5_row10_col0\" class=\"data row10 col0\" >Imputation type</td>\n",
       "      <td id=\"T_e33e5_row10_col1\" class=\"data row10 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e33e5_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_e33e5_row11_col0\" class=\"data row11 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_e33e5_row11_col1\" class=\"data row11 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e33e5_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_e33e5_row12_col0\" class=\"data row12 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_e33e5_row12_col1\" class=\"data row12 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e33e5_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_e33e5_row13_col0\" class=\"data row13 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_e33e5_row13_col1\" class=\"data row13 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e33e5_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_e33e5_row14_col0\" class=\"data row14 col0\" >Fold Number</td>\n",
       "      <td id=\"T_e33e5_row14_col1\" class=\"data row14 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e33e5_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_e33e5_row15_col0\" class=\"data row15 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_e33e5_row15_col1\" class=\"data row15 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e33e5_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_e33e5_row16_col0\" class=\"data row16 col0\" >Use GPU</td>\n",
       "      <td id=\"T_e33e5_row16_col1\" class=\"data row16 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e33e5_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_e33e5_row17_col0\" class=\"data row17 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_e33e5_row17_col1\" class=\"data row17 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e33e5_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_e33e5_row18_col0\" class=\"data row18 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_e33e5_row18_col1\" class=\"data row18 col1\" >clf-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e33e5_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_e33e5_row19_col0\" class=\"data row19 col0\" >USI</td>\n",
       "      <td id=\"T_e33e5_row19_col1\" class=\"data row19 col1\" >c9f9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x77b83077fe20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Saved\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Pipeline(memory=Memory(location=None),\n",
       "          steps=[('label_encoding',\n",
       "                  TransformerWrapperWithInverse(exclude=None, include=None,\n",
       "                                                transformer=LabelEncoder())),\n",
       "                 ('numerical_imputer',\n",
       "                  TransformerWrapper(exclude=None,\n",
       "                                     include=['chroma_stft', 'chroma_cqt',\n",
       "                                              'chroma_cens', 'rmse',\n",
       "                                              'spectral_centroid',\n",
       "                                              'spectral_bandwidth',\n",
       "                                              'spectral_contrast',\n",
       "                                              'spectral_flatness',\n",
       "                                              'spectral_r...\n",
       "                                                               fill_value=None,\n",
       "                                                               keep_empty_features=False,\n",
       "                                                               missing_values=nan,\n",
       "                                                               strategy='most_frequent'))),\n",
       "                 ('trained_model',\n",
       "                  LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                     fit_intercept=True, intercept_scaling=1,\n",
       "                                     l1_ratio=None, max_iter=1000,\n",
       "                                     multi_class='auto', n_jobs=None,\n",
       "                                     penalty='l2', random_state=123,\n",
       "                                     solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                     warm_start=False))],\n",
       "          verbose=False),\n",
       " 'Modelo_LR.pkl')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1 = setup(data=dados, target='label', session_id=123)\n",
    "save_model(lr_model, 'Modelo_LR')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
